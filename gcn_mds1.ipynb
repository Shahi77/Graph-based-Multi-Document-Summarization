{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://gist.github.com/Shahi77/0f29b109b9ac189cb8cb26242106d30f#file-gcn-mds-ipynb",
      "authorship_tag": "ABX9TyNYIe4xSPvmOA2ri4g3bYiD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahi77/Graph-based-Multi-Document-Summarization/blob/main/gcn_mds1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if the files exist\n",
        "print(os.listdir('/content/drive/My Drive/Colab Notebooks/datasets/final/'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovfayXYmvLB3",
        "outputId": "6f24fa9c-80db-46a5-c761-3b231b8fa48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train_final_Vishwas.csv', 'SGM3.ipynb', 'test_final_Vishwas_corrected.json', 'train_final_Vishwas_corrected.json', 'bekaar.ipynb', 'test_final_Vishwas.csv', 'Summaries.zip', 'T5.ipynb', 'minilm_bal_exsum.pth', 'T5_model.pth', 'bekaar_SGM.ipynb', 'SBERT_Model_Ready.pth', 'Summary_Data_new', 'Whole_text_data', 'Summaries']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GGeFtV_ovnQL",
        "outputId": "5541179f-9111-4c14-bdb9-b46c33784f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MDS On Whole_text_data"
      ],
      "metadata": {
        "id": "V5LbPQS7kamK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load spaCy model for English\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "# Path to the dataset\n",
        "summaries_dir = '/content/drive/My Drive/Colab Notebooks/datasets/final/Whole_text_data'\n"
      ],
      "metadata": {
        "id": "rC4abQB3gvB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read document clusters from the dataset directory\n",
        "def read_document_cluster(summaries_dir):\n",
        "    documents = []\n",
        "    summaries_files = os.listdir(summaries_dir)\n",
        "\n",
        "    for file_name in summaries_files:\n",
        "        file_path = os.path.join(summaries_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                documents.append(file.read())\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_name}: {e}\")\n",
        "    return documents"
      ],
      "metadata": {
        "id": "PSMtKPsNhDlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Check if CUDA is available and set device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Function to read document clusters from the dataset directory\n",
        "def read_document_cluster(summaries_dir):\n",
        "    documents = []\n",
        "    summaries_files = os.listdir(summaries_dir)\n",
        "    for file_name in summaries_files:\n",
        "        file_path = os.path.join(summaries_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                documents.append(file.read())\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_name}: {e}\")\n",
        "    return documents\n",
        "\n",
        "# Tokenization using spaCy\n",
        "def tokenize_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "# Get sentence embeddings using spaCy vectors\n",
        "def get_embeddings_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return doc.vector  # Returns a 1D vector of the document\n",
        "\n",
        "# Function to split document into sentences\n",
        "def split_into_sentences(text):\n",
        "    sentences = text.split('.')\n",
        "    return [sentence.strip() for sentence in sentences if sentence]\n",
        "\n",
        "# Custom function to calculate cosine similarity with a threshold\n",
        "def cosine_similarity_threshold(embeddings, threshold=0.2):\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "    adj_matrix = (sim_matrix > threshold).astype(float)  # Apply threshold to create edges\n",
        "    return adj_matrix\n",
        "\n",
        "# Extract sentence features\n",
        "def extract_sentence_features(sentences, nlp):\n",
        "    features = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        length = len(sentence.split())\n",
        "        features.append({\n",
        "            'position': i,\n",
        "            'length': length,\n",
        "            'proper_nouns': sum([1 for token in tokenize_with_spacy(sentence, nlp) if token.isupper()]),\n",
        "            'is_first_three': 1 if i < 3 else 0\n",
        "        })\n",
        "    return features\n",
        "\n",
        "# Calculate sentence personalization score\n",
        "def calculate_personalization_scores(features):\n",
        "    weights = {\n",
        "        'position': 0.1,\n",
        "        'length': 0.2,\n",
        "        'proper_nouns': 0.4,\n",
        "        'is_first_three': 0.3\n",
        "    }\n",
        "    personalization_scores = []\n",
        "    for feature in features:\n",
        "        score = sum([feature[key] * weights[key] for key in weights])\n",
        "        personalization_scores.append(score)\n",
        "    return personalization_scores\n",
        "\n",
        "# Build the sentence relation graph using cosine similarity and personalization\n",
        "def build_sentence_relation_graph(sentences, nlp, threshold=0.2):\n",
        "    print(f\"Building sentence relation graph for {len(sentences)} sentences.\")\n",
        "    sentence_embeddings = [get_embeddings_with_spacy(sentence, nlp) for sentence in sentences]\n",
        "    sentence_embeddings = np.vstack(sentence_embeddings)\n",
        "    print(f\"Shape of sentence embeddings: {sentence_embeddings.shape}\")\n",
        "\n",
        "    adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "    print(f\"Adjacency matrix shape: {adj_matrix.shape}\")\n",
        "\n",
        "    sentence_features = extract_sentence_features(sentences, nlp)\n",
        "    personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "    print(f\"Personalization scores: {personalization_scores}\")\n",
        "\n",
        "    for i in range(adj_matrix.shape[0]):\n",
        "        for j in range(adj_matrix.shape[1]):\n",
        "            if adj_matrix[i, j] > 0:\n",
        "                adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "    adj_matrix = adj_matrix / adj_matrix.max()\n",
        "    print(\"Adjacency matrix normalized.\")\n",
        "    return adj_matrix\n",
        "\n",
        "# GRU-based Sentence Encoder\n",
        "class GRUSentenceEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUSentenceEncoder, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.gru(x)\n",
        "        return h_n.squeeze(0)\n",
        "\n",
        "# Processing document cluster through the GRU\n",
        "def process_document_cluster_through_gru(documents, nlp, hidden_size=128):\n",
        "    input_size = 300  # SpaCy vectors are 300-dimensional\n",
        "    encoder = GRUSentenceEncoder(input_size, hidden_size).to(device)\n",
        "\n",
        "    sentence_encodings = []\n",
        "    for doc in documents:\n",
        "        sentences = split_into_sentences(doc)\n",
        "        sentence_embeddings = [torch.tensor(get_embeddings_with_spacy(sentence, nlp)).to(device) for sentence in sentences]\n",
        "        embeddings_tensor = torch.stack(sentence_embeddings).unsqueeze(0).to(device)\n",
        "\n",
        "        # Ensure that the input tensor shape is correct for GRU\n",
        "        sentence_encoding = encoder(embeddings_tensor)\n",
        "        sentence_encodings.append(sentence_encoding)\n",
        "\n",
        "    return torch.stack(sentence_encodings)\n",
        "\n",
        "\n",
        "# Define GCN Layer\n",
        "class GraphConvolution(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        return output\n",
        "\n",
        "# Define GCN Model\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nout):\n",
        "        super(GCN, self).__init__()\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nout)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.gc1(x, adj)\n",
        "        x = self.relu(x)\n",
        "        x = self.gc2(x, adj)\n",
        "        return x\n",
        "\n",
        "# Define GRU-based Encoder\n",
        "class GRUEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(GRUEncoder, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, hidden = self.gru(x)\n",
        "        return hidden\n",
        "\n",
        "# Load dataset (update path if necessary)\n",
        "summaries_dir = '/content/drive/My Drive/Colab Notebooks/datasets/final/Whole_text_data'\n",
        "\n",
        "# Function to encode a document's sentences\n",
        "def encode_sentences(doc):\n",
        "    vectors = [nlp(sentence.text).vector for sentence in doc.sents]\n",
        "    return torch.tensor(np.array(vectors), dtype=torch.float32)\n",
        "\n",
        "# List to hold sentence encodings and adjacency matrices\n",
        "sentence_encodings_list = []\n",
        "adj_matrix_list = []\n",
        "\n",
        "# Iterate through files in summaries directory\n",
        "for file_name in os.listdir(summaries_dir):\n",
        "    file_path = os.path.join(summaries_dir, file_name)\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Encode sentences\n",
        "        sentence_encodings = encode_sentences(doc)\n",
        "        sentence_encodings_list.append(sentence_encodings)\n",
        "\n",
        "        # Create a random adjacency matrix (replace with actual logic as needed)\n",
        "        num_sentences = sentence_encodings.shape[0]\n",
        "        adj_matrix = torch.eye(num_sentences)  # Identity matrix (can replace with a different adjacency matrix)\n",
        "        adj_matrix_list.append(adj_matrix)\n",
        "\n",
        "# Ensure data is on the correct device (GPU/CPU)\n",
        "sentence_encodings_list = [enc.to(device) for enc in sentence_encodings_list]\n",
        "adj_matrix_list = [adj.to(device) for adj in adj_matrix_list]\n",
        "\n",
        "# Initialize the GCN and GRU models\n",
        "gcn = GCN(nfeat=300, nhid=128, nout=128).to(device)  # Assuming 300-dimensional sentence embeddings\n",
        "gru_encoder = GRUEncoder(input_size=300, hidden_size=128, num_layers=1).to(device)\n",
        "\n",
        "# Example of processing the first document\n",
        "sentence_encodings = sentence_encodings_list[0]\n",
        "adj_matrix = adj_matrix_list[0]\n",
        "\n",
        "# Forward pass through GRU and GCN\n",
        "with torch.no_grad():  # Disable gradients to save memory during inference\n",
        "    # GRU encoder\n",
        "    gru_output = gru_encoder(sentence_encodings.unsqueeze(0))  # Add batch dimension\n",
        "    print(f\"GRU output shape: {gru_output.shape}\")\n",
        "\n",
        "    # GCN layer\n",
        "    gcn_output = gcn(sentence_encodings, adj_matrix)\n",
        "    print(f\"GCN output shape: {gcn_output.shape}\")\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(list(gru_encoder.parameters()) + list(gcn.parameters()), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Example training loop (replace with actual training process as needed)\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass for training (using first document as an example)\n",
        "    gru_output = gru_encoder(sentence_encodings.unsqueeze(0))\n",
        "    gcn_output = gcn(sentence_encodings, adj_matrix)\n",
        "\n",
        "    # Aggregating the GCN output\n",
        "    gcn_output_aggregated = torch.sum(gcn_output, dim=0).unsqueeze(0)  # Shape [1, 128]\n",
        "\n",
        "    # Squeeze GRU output\n",
        "    gru_output_squeezed = gru_output.squeeze(0)  # Shape [1, 128]\n",
        "\n",
        "    # Loss calculation\n",
        "    loss = criterion(gcn_output_aggregated, gru_output_squeezed)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "id": "hlDnM0PS29QO",
        "outputId": "72560951-ba39-4140-eae9-42835cc781ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ad91be04ee65>\u001b[0m in \u001b[0;36m<cell line: 178>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Encode sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0msentence_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0msentence_encodings_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_encodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ad91be04ee65>\u001b[0m in \u001b[0;36mencode_sentences\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;31m# Function to encode a document's sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ad91be04ee65>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;31m# Function to encode a document's sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mtokvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \"\"\"\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mdata_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mdata_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     34\u001b[0m ) -> Tuple[SeqT, Callable]:\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ragged_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_padded_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     89\u001b[0m ) -> Tuple[Ragged, Callable]:\n\u001b[1;32m     90\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mArrayXd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArrayXd\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataXd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdYr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mdata_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mdata_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/hashembed.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, ids, is_train)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mdrop_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NsPJmsF3e73",
        "outputId": "aa81ca86-2359-4cb4-d22d-24ddf201ad10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Read Document Cluster\n",
        "def read_document_cluster(summaries_dir):\n",
        "    documents = []\n",
        "    summaries_files = os.listdir(summaries_dir)\n",
        "    for file_name in summaries_files:\n",
        "        file_path = os.path.join(summaries_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                documents.append(file.read())\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_name}: {e}\")\n",
        "    return documents\n",
        "\n",
        "# 2. Tokenization using spaCy\n",
        "def tokenize_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "# 3. Get Sentence Embeddings\n",
        "def get_embeddings_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return doc.vector  # Returns a 1D vector of the document\n",
        "\n",
        "# 4. Function to Split Document into Sentences\n",
        "def split_into_sentences(text):\n",
        "    sentences = text.split('.')\n",
        "    return [sentence.strip() for sentence in sentences if sentence]\n",
        "\n",
        "# 5. Custom Function to Calculate Cosine Similarity with a Threshold\n",
        "def cosine_similarity_threshold(embeddings, threshold=0.2):\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "    adj_matrix = (sim_matrix > threshold).astype(float)  # Apply threshold to create edges\n",
        "    return adj_matrix\n",
        "\n",
        "# 6. Extract Sentence Features\n",
        "def extract_sentence_features(sentences, nlp):\n",
        "    features = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        length = len(sentence.split())\n",
        "        features.append({\n",
        "            'position': i,\n",
        "            'length': length,\n",
        "            'proper_nouns': sum([1 for token in tokenize_with_spacy(sentence, nlp) if token.isupper()]),\n",
        "            'is_first_three': 1 if i < 3 else 0\n",
        "        })\n",
        "    return features\n",
        "\n",
        "# 7. Calculate Personalization Scores\n",
        "def calculate_personalization_scores(features):\n",
        "    weights = {\n",
        "        'position': 0.1,\n",
        "        'length': 0.2,\n",
        "        'proper_nouns': 0.4,\n",
        "        'is_first_three': 0.3\n",
        "    }\n",
        "    personalization_scores = []\n",
        "    for feature in features:\n",
        "        score = sum([feature[key] * weights[key] for key in weights])\n",
        "        personalization_scores.append(score)\n",
        "    return personalization_scores\n",
        "\n",
        "# 8. Build Sentence Relation Graph\n",
        "def build_sentence_relation_graph(sentences, nlp, threshold=0.2):\n",
        "    print(f\"Building sentence relation graph for {len(sentences)} sentences.\")\n",
        "    sentence_embeddings = [get_embeddings_with_spacy(sentence, nlp) for sentence in sentences]\n",
        "    sentence_embeddings = np.vstack(sentence_embeddings)\n",
        "    print(f\"Shape of sentence embeddings: {sentence_embeddings.shape}\")\n",
        "\n",
        "    adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "    print(f\"Adjacency matrix shape: {adj_matrix.shape}\")\n",
        "\n",
        "    sentence_features = extract_sentence_features(sentences, nlp)\n",
        "    personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "    print(f\"Personalization scores: {personalization_scores}\")\n",
        "\n",
        "    for i in range(adj_matrix.shape[0]):\n",
        "        for j in range(adj_matrix.shape[1]):\n",
        "            if adj_matrix[i, j] > 0:\n",
        "                adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "    adj_matrix = adj_matrix / adj_matrix.max()\n",
        "    print(\"Adjacency matrix normalized.\")\n",
        "    return adj_matrix\n",
        "\n",
        "# 9. GRU-based Sentence Encoder\n",
        "class GRUSentenceEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUSentenceEncoder, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.gru(x)\n",
        "        return h_n.squeeze(0)\n",
        "\n",
        "# 10. Process Document Cluster through GRU\n",
        "def process_document_cluster_through_gru(documents, nlp, hidden_size=128):\n",
        "    input_size = 300  # SpaCy vectors are 300-dimensional\n",
        "    encoder = GRUSentenceEncoder(input_size, hidden_size).to(device)\n",
        "\n",
        "    sentence_encodings = []\n",
        "    for doc in documents:\n",
        "        sentences = split_into_sentences(doc)\n",
        "        sentence_embeddings = [torch.tensor(get_embeddings_with_spacy(sentence, nlp)).to(device) for sentence in sentences]\n",
        "        embeddings_tensor = torch.stack(sentence_embeddings).unsqueeze(0).to(device)\n",
        "\n",
        "        # Ensure that the input tensor shape is correct for GRU\n",
        "        sentence_encoding = encoder(embeddings_tensor)\n",
        "        sentence_encodings.append(sentence_encoding)\n",
        "\n",
        "    return torch.stack(sentence_encodings)\n",
        "\n",
        "# 11. Main Function to Process Documents and Build Graphs\n",
        "def process_documents_and_build_graph(summaries_dir, nlp, hidden_size=128, threshold=0.2):\n",
        "    documents = read_document_cluster(summaries_dir)\n",
        "\n",
        "    # Process each document through GRU\n",
        "    sentence_encodings = process_document_cluster_through_gru(documents, nlp, hidden_size)\n",
        "\n",
        "    for doc_idx, doc in enumerate(documents):  # Changed variable name from 'i' to 'doc_idx'\n",
        "        sentences = split_into_sentences(doc)\n",
        "\n",
        "        # Get sentence embeddings using GRU outputs\n",
        "        sentence_embeddings = sentence_encodings[doc_idx].cpu().detach().numpy()\n",
        "\n",
        "        # Build adjacency matrix using cosine similarity and threshold\n",
        "        adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "\n",
        "        # Extract sentence features for personalization scores\n",
        "        sentence_features = extract_sentence_features(sentences, nlp)\n",
        "        personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "\n",
        "        # Modify adjacency matrix using personalization scores\n",
        "        for i in range(adj_matrix.shape[0]):\n",
        "            for j in range(adj_matrix.shape[1]):\n",
        "                if adj_matrix[i, j] > 0:\n",
        "                    adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "        # Normalize adjacency matrix\n",
        "        adj_matrix = adj_matrix / adj_matrix.max()\n",
        "\n",
        "        print(f\"Processed document {doc_idx + 1}/{len(documents)}\")\n",
        "        print(f\"Adjacency Matrix for Document {doc_idx + 1}:\")\n",
        "        print(adj_matrix)\n",
        "\n",
        "    return sentence_encodings\n",
        "\n",
        "# 12. GCN Layer Definition\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv(x, edge_index)\n",
        "\n",
        "# 13. Integrate GCN with Existing Code\n",
        "def process_with_gcn(sentence_encodings, adj_matrix):\n",
        "    num_sentences = adj_matrix.shape[0]\n",
        "\n",
        "    # Prepare edge index for PyTorch Geometric\n",
        "    edge_index = torch.nonzero(torch.tensor(adj_matrix), as_tuple=False).T\n",
        "    edge_index = edge_index.to(device)\n",
        "\n",
        "    # Convert sentence encodings to tensor\n",
        "    x = torch.tensor(sentence_encodings, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Define GCN model\n",
        "    gcn_model = GCNLayer(in_channels=128, out_channels=64).to(device)  # Adjust hidden size as needed\n",
        "\n",
        "    # Forward pass through GCN\n",
        "    gcn_output = gcn_model(x, edge_index)\n",
        "    return gcn_output\n",
        "\n",
        "# 14. Update Main Processing Function\n",
        "def process_documents_and_build_graph_with_gcn(summaries_dir, nlp, hidden_size=128, threshold=0.2):\n",
        "    documents = read_document_cluster(summaries_dir)\n",
        "\n",
        "    # Process each document through GRU\n",
        "    sentence_encodings = process_document_cluster_through_gru(documents, nlp, hidden_size)\n",
        "\n",
        "    gcn_outputs = []\n",
        "    for i, doc in enumerate(documents):\n",
        "        sentences = split_into_sentences(doc)\n",
        "        sentence_embeddings = sentence_encodings[i].cpu().detach().numpy()\n",
        "\n",
        "        # Build adjacency matrix using cosine similarity and threshold\n",
        "        adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "\n",
        "        # Extract sentence features for personalization scores\n",
        "        sentence_features = extract_sentence_features(sentences, nlp)\n",
        "        personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "\n",
        "        # Modify adjacency matrix using personalization scores\n",
        "        for j in range(adj_matrix.shape[0]):\n",
        "            for k in range(adj_matrix.shape[1]):\n",
        "                if adj_matrix[j, k] > 0:\n",
        "                    adj_matrix[j, k] *= personalization_scores[j]\n",
        "\n",
        "        # Normalize adjacency matrix\n",
        "        adj_matrix = adj_matrix / adj_matrix.max()\n",
        "\n",
        "        # Process with GCN\n",
        "        gcn_output = process_with_gcn(sentence_embeddings, adj_matrix)\n",
        "        gcn_outputs.append(gcn_output)\n",
        "\n",
        "        print(f\"Processed document {i+1}/{len(documents)} with GCN output shape: {gcn_output.shape}\")\n",
        "\n",
        "    return sentence_encodings, gcn_outputs\n",
        "\n",
        "# Example usage\n",
        "summaries_dir = '/content/drive/My Drive/Colab Notebooks/datasets/final/Whole_text_data'\n",
        "nlp = spacy.load(\"en_core_web_md\")  # Load SpaCy model\n",
        "sentence_encodings, gcn_outputs = process_documents_and_build_graph_with_gcn(summaries_dir, nlp)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sCV23240FUs",
        "outputId": "540d8d97-ec93-4889-a3e1-b0dccfd2edff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 2/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 3/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 4/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 5/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 6/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 7/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 8/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 9/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 10/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 11/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 12/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 13/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 14/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 15/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 16/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 17/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 18/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 19/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 20/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 21/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 22/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 23/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 24/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 25/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 26/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 27/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 28/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 29/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 30/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 31/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 32/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 33/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 34/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 35/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 36/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 37/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 38/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 39/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 40/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 41/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 42/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 43/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 44/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 45/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 46/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 47/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 48/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 49/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 50/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 51/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 52/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 53/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 54/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 55/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 56/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 57/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 58/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 59/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 60/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 61/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 62/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 63/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 64/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 65/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 66/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 67/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 68/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 69/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 70/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 71/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 72/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 73/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 74/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 75/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 76/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 77/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 78/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 79/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 80/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 81/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 82/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 83/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 84/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 85/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 86/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 87/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 88/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 89/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 90/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 91/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 92/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 93/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 94/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 95/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 96/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 97/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 98/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 99/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 100/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 101/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 102/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 103/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 104/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 105/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 106/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 107/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 108/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 109/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 110/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 111/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 112/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 113/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 114/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 115/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 116/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 117/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 118/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 119/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 120/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 121/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 122/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 123/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 124/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 125/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 126/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 127/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 128/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 129/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 130/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 131/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 132/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 133/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 134/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 135/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 136/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 137/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 138/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 139/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 140/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 141/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 142/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 143/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 144/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 145/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 146/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 147/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 148/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 149/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 150/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 151/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 152/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 153/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 154/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 155/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 156/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 157/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 158/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 159/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 160/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 161/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 162/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 163/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 164/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 165/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 166/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 167/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 168/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 169/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 170/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 171/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 172/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 173/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 174/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 175/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 176/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 177/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 178/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 179/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 180/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 181/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 182/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 183/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 184/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 185/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 186/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 187/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 188/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 189/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 190/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 191/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 192/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 193/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 194/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 195/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 196/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 197/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 198/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 199/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 200/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 201/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 202/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 203/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 204/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 205/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 206/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 207/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 208/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 209/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 210/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 211/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 212/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 213/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 214/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 215/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 216/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 217/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 218/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 219/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 220/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 221/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 222/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 223/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 224/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 225/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 226/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 227/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 228/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 229/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 230/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 231/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 232/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 233/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 234/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 235/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 236/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 237/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 238/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 239/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 240/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 241/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 242/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 243/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 244/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 245/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 246/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 247/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 248/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 249/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 250/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 251/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 252/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 253/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 254/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 255/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 256/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 257/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 258/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 259/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 260/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 261/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 262/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 263/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 264/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 265/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 266/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 267/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 268/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 269/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 270/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 271/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 272/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 273/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 274/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 275/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 276/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 277/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 278/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 279/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 280/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 281/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 282/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 283/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 284/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 285/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 286/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 287/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 288/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 289/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 290/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 291/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 292/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 293/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 294/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 295/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 296/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 297/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 298/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 299/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 300/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 301/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 302/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 303/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 304/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 305/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 306/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 307/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 308/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 309/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 310/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 311/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 312/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 313/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 314/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 315/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 316/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 317/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 318/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 319/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 320/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 321/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 322/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 323/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 324/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 325/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 326/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 327/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 328/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 329/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 330/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 331/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 332/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 333/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 334/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 335/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 336/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 337/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 338/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 339/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 340/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 341/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 342/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 343/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 344/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 345/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 346/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 347/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 348/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 349/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 350/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 351/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 352/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 353/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 354/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 355/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 356/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 357/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 358/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 359/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 360/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 361/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 362/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 363/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 364/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 365/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 366/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 367/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 368/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 369/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 370/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 371/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 372/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 373/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 374/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 375/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 376/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 377/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 378/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 379/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 380/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 381/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 382/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 383/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 384/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 385/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 386/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 387/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 388/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 389/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 390/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 391/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 392/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 393/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 394/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 395/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 396/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 397/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 398/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 399/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 400/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 401/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 402/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 403/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 404/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 405/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 406/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 407/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 408/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 409/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 410/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 411/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 412/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 413/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 414/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 415/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 416/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 417/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 418/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 419/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 420/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 421/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 422/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 423/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 424/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 425/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 426/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 427/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 428/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 429/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 430/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 431/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 432/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 433/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 434/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 435/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 436/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 437/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 438/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 439/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 440/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 441/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 442/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 443/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 444/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 445/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 446/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 447/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 448/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 449/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 450/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 451/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 452/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 453/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 454/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 455/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 456/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 457/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 458/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 459/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 460/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 461/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 462/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 463/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 464/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 465/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 466/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 467/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 468/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 469/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 470/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 471/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 472/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 473/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 474/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 475/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 476/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 477/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 478/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 479/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 480/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 481/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 482/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 483/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 484/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 485/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 486/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 487/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 488/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 489/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 490/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 491/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 492/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 493/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 494/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 495/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 496/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 497/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 498/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 499/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 500/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 501/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 502/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 503/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 504/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 505/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 506/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 507/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 508/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 509/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 510/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 511/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 512/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 513/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 514/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 515/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 516/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 517/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 518/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 519/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 520/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 521/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 522/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 523/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 524/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 525/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 526/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 527/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 528/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 529/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 530/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 531/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 532/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 533/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 534/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 535/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 536/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 537/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 538/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 539/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 540/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 541/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 542/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 543/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 544/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 545/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 546/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 547/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 548/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 549/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 550/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 551/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 552/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 553/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 554/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 555/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 556/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 557/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 558/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 559/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 560/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 561/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 562/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 563/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 564/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 565/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 566/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 567/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 568/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 569/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 570/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 571/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 572/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 573/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 574/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 575/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 576/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 577/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 578/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 579/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 580/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 581/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 582/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 583/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 584/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 585/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 586/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 587/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 588/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 589/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 590/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 591/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 592/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 593/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 594/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 595/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 596/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 597/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 598/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 599/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 600/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 601/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 602/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 603/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 604/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 605/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 606/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 607/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 608/608 with GCN output shape: torch.Size([1, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using np.array\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Read Document Cluster\n",
        "def read_document_cluster(summaries_dir):\n",
        "    documents = []\n",
        "    summaries_files = os.listdir(summaries_dir)\n",
        "    for file_name in summaries_files:\n",
        "        file_path = os.path.join(summaries_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                documents.append(file.read())\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_name}: {e}\")\n",
        "    return documents\n",
        "\n",
        "# 2. Tokenization using spaCy\n",
        "def tokenize_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "# 3. Get Sentence Embeddings\n",
        "def get_embeddings_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return doc.vector  # Returns a 1D vector of the document\n",
        "\n",
        "# 4. Function to Split Document into Sentences\n",
        "def split_into_sentences(text):\n",
        "    return [sentence.strip() for sentence in text.split('.') if sentence]\n",
        "\n",
        "# 5. Custom Function to Calculate Cosine Similarity with a Threshold\n",
        "def cosine_similarity_threshold(embeddings, threshold=0.2):\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "    return (sim_matrix > threshold).astype(float)  # Apply threshold to create edges\n",
        "\n",
        "# 6. Extract Sentence Features\n",
        "def extract_sentence_features(sentences, nlp):\n",
        "    features = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        length = len(sentence.split())\n",
        "        features.append({\n",
        "            'position': i,\n",
        "            'length': length,\n",
        "            'proper_nouns': sum([1 for token in tokenize_with_spacy(sentence, nlp) if token.isupper()]),\n",
        "            'is_first_three': 1 if i < 3 else 0\n",
        "        })\n",
        "    return np.array(features)\n",
        "\n",
        "# 7. Calculate Personalization Scores\n",
        "def calculate_personalization_scores(features):\n",
        "    weights = {\n",
        "        'position': 0.1,\n",
        "        'length': 0.2,\n",
        "        'proper_nouns': 0.4,\n",
        "        'is_first_three': 0.3\n",
        "    }\n",
        "    scores = []\n",
        "    for feature in features:\n",
        "        score = sum(feature[key] * weights[key] for key in weights)\n",
        "        scores.append(score)\n",
        "    return np.array(scores)\n",
        "\n",
        "# 8. Build Sentence Relation Graph\n",
        "def build_sentence_relation_graph(sentences, nlp, threshold=0.2):\n",
        "    print(f\"Building sentence relation graph for {len(sentences)} sentences.\")\n",
        "    sentence_embeddings = np.array([get_embeddings_with_spacy(sentence, nlp) for sentence in sentences])\n",
        "    adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "\n",
        "    sentence_features = extract_sentence_features(sentences, nlp)\n",
        "    personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "\n",
        "    # Modify adjacency matrix using personalization scores\n",
        "    for i in range(adj_matrix.shape[0]):\n",
        "        for j in range(adj_matrix.shape[1]):\n",
        "            if adj_matrix[i, j] > 0:\n",
        "                adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "    # Normalize adjacency matrix\n",
        "    adj_matrix = adj_matrix / np.max(adj_matrix) if np.max(adj_matrix) > 0 else adj_matrix\n",
        "    return adj_matrix\n",
        "\n",
        "# 9. GRU-based Sentence Encoder\n",
        "class GRUSentenceEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUSentenceEncoder, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.gru(x)\n",
        "        return h_n.squeeze(0)\n",
        "\n",
        "# 10. Process Document Cluster through GRU\n",
        "def process_document_cluster_through_gru(documents, nlp, hidden_size=128):\n",
        "    input_size = 300  # SpaCy vectors are 300-dimensional\n",
        "    encoder = GRUSentenceEncoder(input_size, hidden_size).to(device)\n",
        "\n",
        "    sentence_encodings = []\n",
        "    for doc in documents:\n",
        "        sentences = split_into_sentences(doc)\n",
        "        sentence_embeddings = np.array([get_embeddings_with_spacy(sentence, nlp) for sentence in sentences])\n",
        "\n",
        "        # Ensure that the input tensor shape is correct for GRU\n",
        "        embeddings_tensor = torch.tensor(sentence_embeddings, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        sentence_encoding = encoder(embeddings_tensor)\n",
        "\n",
        "        sentence_encodings.append(sentence_encoding.cpu().detach().numpy())\n",
        "\n",
        "    return np.array(sentence_encodings)\n",
        "\n",
        "# 11. Main Function to Process Documents and Build Graphs\n",
        "def process_documents_and_build_graph(summaries_dir, nlp, hidden_size=128, threshold=0.2):\n",
        "    documents = read_document_cluster(summaries_dir)\n",
        "\n",
        "    # Process each document through GRU\n",
        "    sentence_encodings = process_document_cluster_through_gru(documents, nlp, hidden_size)\n",
        "\n",
        "    for i, doc in enumerate(documents):\n",
        "        sentences = split_into_sentences(doc)\n",
        "        # Get sentence embeddings using GRU outputs\n",
        "        sentence_embeddings = sentence_encodings[i]\n",
        "\n",
        "        # Build adjacency matrix using cosine similarity and threshold\n",
        "        adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "\n",
        "        # Extract sentence features for personalization scores\n",
        "        sentence_features = extract_sentence_features(sentences, nlp)\n",
        "        personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "\n",
        "        # Modify adjacency matrix using personalization scores\n",
        "        for i in range(adj_matrix.shape[0]):\n",
        "            for j in range(adj_matrix.shape[1]):\n",
        "                if adj_matrix[i, j] > 0:\n",
        "                    adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "        # Normalize adjacency matrix\n",
        "        adj_matrix = adj_matrix / np.max(adj_matrix) if np.max(adj_matrix) > 0 else adj_matrix\n",
        "\n",
        "       # print(f\"Processed document {i+1}/{len(documents)}\")\n",
        "       # print(f\"Adjacency Matrix for Document {i+1}:\")\n",
        "        print(adj_matrix)\n",
        "\n",
        "    return sentence_encodings\n",
        "\n",
        "# 12. GCN Layer Definition\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv(x, edge_index)\n",
        "\n",
        "# 13. Integrate GCN with Existing Code\n",
        "def process_with_gcn(sentence_encodings, adj_matrix):\n",
        "    num_sentences = adj_matrix.shape[0]\n",
        "\n",
        "    # Prepare edge index for PyTorch Geometric\n",
        "    edge_index = torch.nonzero(torch.tensor(adj_matrix), as_tuple=False).T\n",
        "    edge_index = edge_index.to(device)\n",
        "\n",
        "    # Convert sentence encodings to tensor\n",
        "    x = torch.tensor(sentence_encodings, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Define GCN model\n",
        "    gcn_model = GCNLayer(in_channels=128, out_channels=64).to(device)\n",
        "\n",
        "    # Forward pass through GCN\n",
        "    gcn_output = gcn_model(x, edge_index)\n",
        "    return gcn_output\n",
        "\n",
        "# 14. Update Main Processing Function\n",
        "def process_documents_and_build_graph_with_gcn(summaries_dir, nlp, hidden_size=128, threshold=0.2):\n",
        "    documents = read_document_cluster(summaries_dir)\n",
        "\n",
        "    # Process each document through GRU\n",
        "    sentence_encodings = process_document_cluster_through_gru(documents, nlp, hidden_size)\n",
        "\n",
        "    gcn_outputs = []\n",
        "    for i, doc in enumerate(documents):\n",
        "        sentences = split_into_sentences(doc)\n",
        "        sentence_embeddings = sentence_encodings[i]\n",
        "\n",
        "        # Build adjacency matrix using cosine similarity and threshold\n",
        "        adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "\n",
        "        # Extract sentence features for personalization scores\n",
        "        sentence_features = extract_sentence_features(sentences, nlp)\n",
        "        personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "\n",
        "        # Modify adjacency matrix using personalization scores\n",
        "        for i in range(adj_matrix.shape[0]):\n",
        "            for j in range(adj_matrix.shape[1]):\n",
        "                if adj_matrix[i, j] > 0:\n",
        "                    adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "        # Normalize adjacency matrix\n",
        "        adj_matrix = adj_matrix / np.max(adj_matrix) if np.max(adj_matrix) > 0 else adj_matrix\n",
        "\n",
        "        # Process with GCN\n",
        "        gcn_output = process_with_gcn(sentence_embeddings, adj_matrix)\n",
        "        gcn_outputs.append(gcn_output.cpu().detach().numpy())\n",
        "\n",
        "        print(f\"Processed document {i+1}/{len(documents)} with GCN output shape: {gcn_output.shape}\")\n",
        "\n",
        "    return sentence_encodings, gcn_outputs\n",
        "\n",
        "# Example usage\n",
        "summaries_dir = '/content/drive/My Drive/Colab Notebooks/datasets/final/Whole_text_data'\n",
        "nlp = spacy.load(\"en_core_web_md\")  # Load SpaCy model\n",
        "sentence_encodings, gcn_outputs = process_documents_and_build_graph_with_gcn(summaries_dir, nlp)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CPsa_tv8AMlg",
        "outputId": "b5b31b4f-df3b-4de0-cdba-86ffc0a7e64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n",
            "Processed document 1/608 with GCN output shape: torch.Size([1, 64])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-7-3b886bf02917>\", line 219, in <cell line: 219>\n",
            "    sentence_encodings, gcn_outputs = process_documents_and_build_graph_with_gcn(summaries_dir, nlp)\n",
            "  File \"<ipython-input-7-3b886bf02917>\", line 196, in process_documents_and_build_graph_with_gcn\n",
            "    sentence_features = extract_sentence_features(sentences, nlp)\n",
            "  File \"<ipython-input-7-3b886bf02917>\", line 53, in extract_sentence_features\n",
            "    'proper_nouns': sum([1 for token in tokenize_with_spacy(sentence, nlp) if token.isupper()]),\n",
            "  File \"<ipython-input-7-3b886bf02917>\", line 28, in tokenize_with_spacy\n",
            "    doc = nlp(text)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/language.py\", line 1049, in __call__\n",
            "    doc = proc(doc, **component_cfg.get(name, {}))  # type: ignore[call-arg]\n",
            "  File \"spacy/pipeline/trainable_pipe.pyx\", line 52, in spacy.pipeline.trainable_pipe.TrainablePipe.__call__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/pipeline/tok2vec.py\", line 126, in predict\n",
            "    tokvecs = self.model.predict(docs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 334, in predict\n",
            "    return self._func(self, X, is_train=False)[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\", line 54, in forward\n",
            "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 310, in __call__\n",
            "    return self._func(self, X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\", line 54, in forward\n",
            "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 310, in __call__\n",
            "    return self._func(self, X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\", line 57, in forward\n",
            "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\", line 57, in <listcomp>\n",
            "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 310, in __call__\n",
            "    return self._func(self, X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\", line 54, in forward\n",
            "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 310, in __call__\n",
            "    return self._func(self, X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\", line 36, in forward\n",
            "    return cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\", line 91, in _ragged_forward\n",
            "    Y, get_dX = layer(Xr.dataXd, is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 310, in __call__\n",
            "    return self._func(self, X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\", line 57, in forward\n",
            "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\", line 57, in <listcomp>\n",
            "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 310, in __call__\n",
            "    return self._func(self, X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\", line 54, in forward\n",
            "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 310, in __call__\n",
            "    return self._func(self, X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/hashembed.py\", line 72, in forward\n",
            "    output = model.ops.gather_add(vectors, keys)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1624, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
            "    lines = linecache.getlines(file, globals_dict)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3b886bf02917>\u001b[0m in \u001b[0;36m<cell line: 219>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_md\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load SpaCy model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m \u001b[0msentence_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_documents_and_build_graph_with_gcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3b886bf02917>\u001b[0m in \u001b[0;36mprocess_documents_and_build_graph_with_gcn\u001b[0;34m(summaries_dir, nlp, hidden_size, threshold)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# Extract sentence features for personalization scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0msentence_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_sentence_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mpersonalization_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_personalization_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3b886bf02917>\u001b[0m in \u001b[0;36mextract_sentence_features\u001b[0;34m(sentences, nlp)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;34m'length'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;34m'proper_nouns'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize_with_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;34m'is_first_three'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3b886bf02917>\u001b[0m in \u001b[0;36mtokenize_with_spacy\u001b[0;34m(text, nlp)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_with_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mtokvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokvecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \"\"\"\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ragged_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mArrayXd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArrayXd\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataXd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    309\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/thinc/layers/hashembed.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, ids, is_train)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mdrop_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Read Document Cluster\n",
        "def read_document_cluster(summaries_dir):\n",
        "    documents = []\n",
        "    summaries_files = os.listdir(summaries_dir)\n",
        "    for file_name in summaries_files:\n",
        "        file_path = os.path.join(summaries_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                documents.append(file.read())\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_name}: {e}\")\n",
        "    return documents\n",
        "\n",
        "# 2. Tokenization using spaCy\n",
        "def tokenize_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "# 3. Get Sentence Embeddings\n",
        "def get_embeddings_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return doc.vector  # Returns a 1D vector of the document\n",
        "\n",
        "# 4. Function to Split Document into Sentences\n",
        "def split_into_sentences(text):\n",
        "    sentences = text.split('.')\n",
        "    return [sentence.strip() for sentence in sentences if sentence]\n",
        "\n",
        "# 5. Custom Function to Calculate Cosine Similarity with a Threshold\n",
        "def cosine_similarity_threshold(embeddings, threshold=0.2):\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "    adj_matrix = (sim_matrix > threshold).astype(float)  # Apply threshold to create edges\n",
        "    return adj_matrix\n",
        "\n",
        "# 6. Extract Sentence Features\n",
        "def extract_sentence_features(sentences, nlp):\n",
        "    features = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        length = len(sentence.split())\n",
        "        features.append({\n",
        "            'position': i,\n",
        "            'length': length,\n",
        "            'proper_nouns': sum([1 for token in tokenize_with_spacy(sentence, nlp) if token.isupper()]),\n",
        "            'is_first_three': 1 if i < 3 else 0\n",
        "        })\n",
        "    return features\n",
        "\n",
        "# 7. Calculate Personalization Scores\n",
        "def calculate_personalization_scores(features):\n",
        "    weights = {\n",
        "        'position': 0.1,\n",
        "        'length': 0.2,\n",
        "        'proper_nouns': 0.4,\n",
        "        'is_first_three': 0.3\n",
        "    }\n",
        "    personalization_scores = []\n",
        "    for feature in features:\n",
        "        score = sum([feature[key] * weights[key] for key in weights])\n",
        "        personalization_scores.append(score)\n",
        "    return personalization_scores\n",
        "\n",
        "# 8. Build Sentence Relation Graph\n",
        "def build_sentence_relation_graph(sentences, nlp, threshold=0.2):\n",
        "    print(f\"Building sentence relation graph for {len(sentences)} sentences.\")\n",
        "    sentence_embeddings = [get_embeddings_with_spacy(sentence, nlp) for sentence in sentences]\n",
        "    sentence_embeddings = np.vstack(sentence_embeddings)\n",
        "    print(f\"Shape of sentence embeddings: {sentence_embeddings.shape}\")\n",
        "\n",
        "    adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "    print(f\"Adjacency matrix shape: {adj_matrix.shape}\")\n",
        "\n",
        "    sentence_features = extract_sentence_features(sentences, nlp)\n",
        "    personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "    print(f\"Personalization scores: {personalization_scores}\")\n",
        "\n",
        "    # Modify adjacency matrix using personalization scores\n",
        "    for i in range(adj_matrix.shape[0]):\n",
        "        for j in range(adj_matrix.shape[1]):\n",
        "            if adj_matrix[i, j] > 0:\n",
        "                adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "    adj_matrix = adj_matrix / adj_matrix.max() if adj_matrix.max() > 0 else adj_matrix\n",
        "    print(\"Adjacency matrix normalized.\")\n",
        "    return adj_matrix\n",
        "\n",
        "# 9. GRU-based Sentence Encoder\n",
        "class GRUSentenceEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUSentenceEncoder, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.gru(x)\n",
        "        return h_n.squeeze(0)\n",
        "\n",
        "# 10. Process Document Cluster through GRU\n",
        "def process_document_cluster_through_gru(documents, nlp, hidden_size=128):\n",
        "    input_size = 300  # SpaCy vectors are 300-dimensional\n",
        "    encoder = GRUSentenceEncoder(input_size, hidden_size).to(device)\n",
        "\n",
        "    sentence_encodings = []\n",
        "    for doc in documents:\n",
        "        sentences = split_into_sentences(doc)\n",
        "        sentence_embeddings = [torch.tensor(get_embeddings_with_spacy(sentence, nlp)).to(device).unsqueeze(0) for sentence in sentences]\n",
        "        embeddings_tensor = torch.cat(sentence_embeddings, dim=0).unsqueeze(0).to(device)\n",
        "\n",
        "        # Ensure that the input tensor shape is correct for GRU\n",
        "        sentence_encoding = encoder(embeddings_tensor)\n",
        "        sentence_encodings.append(sentence_encoding)\n",
        "\n",
        "    return torch.stack(sentence_encodings)\n",
        "\n",
        "# 11. Main Function to Process Documents and Build Graphs\n",
        "def process_documents_and_build_graph(summaries_dir, nlp, hidden_size=128, threshold=0.2):\n",
        "    documents = read_document_cluster(summaries_dir)\n",
        "\n",
        "    # Process each document through GRU\n",
        "    sentence_encodings = process_document_cluster_through_gru(documents, nlp, hidden_size)\n",
        "\n",
        "    for i, doc in enumerate(documents):\n",
        "        sentences = split_into_sentences(doc)\n",
        "        # Get sentence embeddings using GRU outputs\n",
        "        sentence_embeddings = sentence_encodings[i].cpu().detach().numpy()\n",
        "\n",
        "        # Build adjacency matrix using cosine similarity and threshold\n",
        "        adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "\n",
        "        # Extract sentence features for personalization scores\n",
        "        sentence_features = extract_sentence_features(sentences, nlp)\n",
        "        personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "\n",
        "        # Modify adjacency matrix using personalization scores\n",
        "        for i in range(adj_matrix.shape[0]):\n",
        "            for j in range(adj_matrix.shape[1]):\n",
        "                if adj_matrix[i, j] > 0:\n",
        "                    adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "        # Normalize adjacency matrix\n",
        "        adj_matrix = adj_matrix / adj_matrix.max() if adj_matrix.max() > 0 else adj_matrix\n",
        "\n",
        "       # print(f\"Processed document {i + 1}/{len(documents)}\")\n",
        "        #print(f\"Adjacency Matrix for Document {i + 1}:\")\n",
        "        print(adj_matrix)\n",
        "\n",
        "    return sentence_encodings\n",
        "\n",
        "# 12. GCN Layer Definition\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        return self.conv(x, edge_index)\n",
        "\n",
        "# 13. Integrate GCN with Existing Code\n",
        "def process_with_gcn(sentence_encodings, adj_matrix):\n",
        "    num_sentences = adj_matrix.shape[0]\n",
        "\n",
        "    # Prepare edge index for PyTorch Geometric\n",
        "    edge_index = torch.nonzero(torch.tensor(adj_matrix), as_tuple=False).T\n",
        "    edge_index = edge_index.to(device)\n",
        "\n",
        "    # Convert sentence encodings to tensor\n",
        "    x = torch.tensor(sentence_encodings, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Define GCN model\n",
        "    gcn_model = GCNLayer(in_channels=128, out_channels=64).to(device)  # Adjust hidden size as needed\n",
        "\n",
        "    # Forward pass through GCN\n",
        "    gcn_output = gcn_model(x, edge_index)\n",
        "    return gcn_output\n",
        "\n",
        "# 14. Update Main Processing Function\n",
        "def process_documents_and_build_graph_with_gcn(summaries_dir, nlp, hidden_size=128, threshold=0.2):\n",
        "    documents = read_document_cluster(summaries_dir)\n",
        "\n",
        "    # Process each document through GRU\n",
        "    sentence_encodings = process_document_cluster_through_gru(documents, nlp, hidden_size)\n",
        "\n",
        "    gcn_outputs = []\n",
        "    for i, doc in enumerate(documents):\n",
        "        sentences = split_into_sentences(doc)\n",
        "        sentence_embeddings = sentence_encodings[i].cpu().detach().numpy()\n",
        "\n",
        "        # Build adjacency matrix using cosine similarity and threshold\n",
        "        adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "\n",
        "        # Extract sentence features for personalization scores\n",
        "        sentence_features = extract_sentence_features(sentences, nlp)\n",
        "        personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "\n",
        "        # Modify adjacency matrix using personalization scores\n",
        "        for i in range(adj_matrix.shape[0]):\n",
        "            for j in range(adj_matrix.shape[1]):\n",
        "                if adj_matrix[i, j] > 0:\n",
        "                    adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "        # Normalize adjacency matrix\n",
        "        adj_matrix = adj_matrix / adj_matrix.max() if adj_matrix.max() > 0 else adj_matrix\n",
        "\n",
        "        # Process with GCN\n",
        "        gcn_output = process_with_gcn(sentence_embeddings, adj_matrix)\n",
        "        gcn_outputs.append(gcn_output)\n",
        "\n",
        "        print(f\"Processed document {i + 1}/{len(documents)} with GCN output shape: {gcn_output.shape}\")\n",
        "\n",
        "    return sentence_encodings, gcn_outputs\n",
        "\n",
        "# Example usage\n",
        "summaries_dir = '/content/drive/My Drive/Colab Notebooks/datasets/final/Whole_text_data'\n",
        "nlp = spacy.load(\"en_core_web_md\")  # Load SpaCy model\n",
        "sentence_encodings, gcn_outputs = process_documents_and_build_graph_with_gcn(summaries_dir, nlp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "qsqsTq6GASYo",
        "outputId": "f0627835-87b5-4746-cf47-15de2866a0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_geometric'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-56ec9b09cff7>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Define device for computation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Function to read document clusters from the dataset directory\n",
        "def read_document_cluster(summaries_dir):\n",
        "    documents = []\n",
        "    summaries_files = os.listdir(summaries_dir)\n",
        "\n",
        "    for file_name in summaries_files:\n",
        "        file_path = os.path.join(summaries_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                documents.append(file.read())\n",
        "           # print(f\"Loaded {file_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_name}: {e}\")\n",
        "    return documents\n",
        "\n",
        "# Tokenization using spaCy\n",
        "def tokenize_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "# Get sentence embeddings using spaCy vectors\n",
        "def get_embeddings_with_spacy(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    return doc.vector  # Returns a 1D vector of the document\n",
        "\n",
        "# Function to split document into sentences\n",
        "def split_into_sentences(text):\n",
        "    sentences = text.split('.')\n",
        "    return [sentence.strip() for sentence in sentences if sentence]\n",
        "\n",
        "# Custom function to calculate cosine similarity with a threshold\n",
        "def cosine_similarity_threshold(embeddings, threshold=0.2):\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "    adj_matrix = (sim_matrix > threshold).astype(float)  # Apply threshold to create edges\n",
        "    return adj_matrix\n",
        "\n",
        "# Extract sentence features\n",
        "def extract_sentence_features(sentences, nlp):\n",
        "    features = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        length = len(sentence.split())\n",
        "        features.append({\n",
        "            'position': i,\n",
        "            'length': length,\n",
        "            'proper_nouns': sum([1 for token in tokenize_with_spacy(sentence, nlp) if token.isupper()]),\n",
        "            'is_first_three': 1 if i < 3 else 0\n",
        "        })\n",
        "    return features\n",
        "\n",
        "# Calculate sentence personalization score\n",
        "def calculate_personalization_scores(features):\n",
        "    weights = {\n",
        "        'position': 0.1,\n",
        "        'length': 0.2,\n",
        "        'proper_nouns': 0.4,\n",
        "        'is_first_three': 0.3\n",
        "    }\n",
        "    personalization_scores = []\n",
        "    for feature in features:\n",
        "        score = sum([feature[key] * weights[key] for key in weights])\n",
        "        personalization_scores.append(score)\n",
        "    return personalization_scores\n",
        "\n",
        "# Build the sentence relation graph using cosine similarity and personalization\n",
        "def build_sentence_relation_graph(sentences, nlp, threshold=0.2):\n",
        "    print(f\"Building sentence relation graph for {len(sentences)} sentences.\")\n",
        "    sentence_embeddings = [get_embeddings_with_spacy(sentence, nlp) for sentence in sentences]\n",
        "    sentence_embeddings = np.vstack(sentence_embeddings)\n",
        "    print(f\"Shape of sentence embeddings: {sentence_embeddings.shape}\")\n",
        "\n",
        "    adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "    print(f\"Adjacency matrix shape: {adj_matrix.shape}\")\n",
        "\n",
        "    sentence_features = extract_sentence_features(sentences, nlp)\n",
        "    personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "    print(f\"Personalization scores: {personalization_scores}\")\n",
        "\n",
        "    for i in range(adj_matrix.shape[0]):\n",
        "        for j in range(adj_matrix.shape[1]):\n",
        "            if adj_matrix[i, j] > 0:\n",
        "                adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "    adj_matrix = adj_matrix / adj_matrix.max()\n",
        "    print(\"Adjacency matrix normalized.\")\n",
        "    return adj_matrix\n",
        "\n",
        "# GRU-based Sentence Encoder\n",
        "class GRUSentenceEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUSentenceEncoder, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.gru(x)\n",
        "        return h_n.squeeze(0)\n",
        "\n",
        "# Processing document cluster through the GRU\n",
        "def process_document_cluster_through_gru(documents, nlp, hidden_size=128):\n",
        "    input_size = 300  # SpaCy vectors are 300-dimensional\n",
        "    encoder = GRUSentenceEncoder(input_size, hidden_size).to(device)\n",
        "\n",
        "    sentence_encodings = []\n",
        "    for doc in documents:\n",
        "        sentences = split_into_sentences(doc)\n",
        "       # print(f\"Processing document with {len(sentences)} sentences.\")\n",
        "        sentence_embeddings = [torch.tensor(get_embeddings_with_spacy(sentence, nlp)).to(device) for sentence in sentences]\n",
        "        embeddings_tensor = torch.stack(sentence_embeddings).unsqueeze(0).to(device)\n",
        "\n",
        "        # Ensure that the input tensor shape is correct for GRU\n",
        "        sentence_encoding = encoder(embeddings_tensor)\n",
        "        sentence_encodings.append(sentence_encoding)\n",
        "\n",
        "    return torch.stack(sentence_encodings)\n",
        "\n",
        "# GCN Layer Definition\n",
        "# class GCNLayer(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(GCNLayer, self).__init__()\n",
        "#         self.fc = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "#    def forward(self, x, adj):\n",
        "#     # Normalize the adjacency matrix\n",
        "#       adj = self.normalize_adj(adj)\n",
        "\n",
        "#     # Check shapes before multiplication\n",
        "#     print(f\"Shape of adj: {adj.shape}, Shape of x: {x.shape}\")\n",
        "\n",
        "#     # Ensure dimensions match\n",
        "#     if adj.shape[0] != x.shape[0]:\n",
        "#         raise ValueError(f\"Dimension mismatch: adj has {adj.shape[0]} nodes, but x has {x.shape[0]} features.\")\n",
        "\n",
        "#     # Perform the multiplication\n",
        "#        x = torch.matmul(adj, x)\n",
        "#        return F.relu(x)\n",
        "\n",
        "#     def normalize_adj(self, adj):\n",
        "#         num_nodes = adj.size(0)\n",
        "#         I = torch.eye(num_nodes).to(device)\n",
        "#         adj = adj + I\n",
        "#         D = torch.sum(adj, dim=1)\n",
        "#         D_inv_sqrt = torch.pow(D, -0.5)\n",
        "#         D_inv_sqrt[torch.isinf(D_inv_sqrt)] = 0\n",
        "#         D_inv_sqrt = torch.diag(D_inv_sqrt)\n",
        "#         return torch.matmul(D_inv_sqrt, torch.matmul(adj, D_inv_sqrt))\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.fc = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        adj = self.normalize_adj(adj)\n",
        "        assert adj.shape[0] == x.shape[0], \"Dimension mismatch: adj and x must have the same number of nodes.\"\n",
        "\n",
        "        x = torch.matmul(adj, x)\n",
        "        return F.relu(x)\n",
        "\n",
        "    def normalize_adj(self, adj):\n",
        "        num_nodes = adj.size(0)\n",
        "        I = torch.eye(num_nodes).to(device)\n",
        "        adj = adj + I\n",
        "        D = torch.sum(adj, dim=1)\n",
        "        D_inv_sqrt = torch.pow(D, -0.5)\n",
        "        D_inv_sqrt[torch.isinf(D_inv_sqrt)] = 0\n",
        "        D_inv_sqrt = torch.diag(D_inv_sqrt)\n",
        "        return torch.matmul(D_inv_sqrt, torch.matmul(adj, D_inv_sqrt))\n",
        "\n",
        "\n",
        "# Read and process documents\n",
        "summaries_dir = '/content/drive/My Drive/Colab Notebooks/datasets/final/Whole_text_data'\n",
        "documents = read_document_cluster(summaries_dir)\n",
        "print(f\"Loaded {len(documents)} documents.\")\n",
        "\n",
        "# Initialize spaCy\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "# Split documents into sentences\n",
        "sentences_per_document = [split_into_sentences(doc) for doc in documents]\n",
        "print(\"Done splitting documents into sentences.\")\n",
        "\n",
        "# Build sentence relation graphs for each document\n",
        "adj_matrices = [build_sentence_relation_graph(sentences, nlp) for sentences in sentences_per_document]\n",
        "print(\"Done building adjacency matrices.\")\n",
        "\n",
        "# Process documents through GRU\n",
        "sentence_encodings = process_document_cluster_through_gru(documents, nlp, hidden_size=128)\n",
        "print(f\"Processed document clusters through GRU. Shape: {sentence_encodings.shape}\")\n",
        "\n",
        "# Example usage of GCN layer\n",
        "gcn = GCNLayer(128, 64).to(device)\n",
        "# Convert adj_matrices to tensor and move to device\n",
        "adj_tensor = torch.tensor(adj_matrices[0], dtype=torch.float32).to(device)\n",
        "\n",
        "# Check the shape of the sentence encodings\n",
        "print(f\"Shape of sentence_encodings before: {sentence_encodings.shape}\")\n",
        "\n",
        "# Ensure the encodings have the correct dimensions [608, 128]\n",
        "if len(sentence_encodings.shape) == 3 and sentence_encodings.shape[1] == 1:\n",
        "    sentence_encodings = sentence_encodings.squeeze(1)  # Remove the second dimension\n",
        "\n",
        "# Verify the final shape of sentence_encodings\n",
        "print(f\"Shape of sentence_encodings after: {sentence_encodings.shape}\")\n",
        "\n",
        "# Ensure adj_tensor has the right dimensions\n",
        "print(f\"Shape of adj_tensor: {adj_tensor.shape}\")\n",
        "\n",
        "# Apply the GCN layer to the sentence encodings and adjacency matrix\n",
        "gcn_output = gcn(sentence_encodings, adj_tensor)\n",
        "\n",
        "# Print the shape of the output\n",
        "print(\"GCN output shape: \", gcn_output.shape)"
      ],
      "metadata": {
        "id": "5tidvqUIp4Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization using spaCy\n",
        "def tokenize_with_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.text for token in doc]\n",
        "\n",
        "# Get sentence embeddings using spaCy vectors\n",
        "def get_embeddings_with_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    return doc.vector  # Returns a 1D vector of the document\n",
        "\n",
        "# Function to split document into sentences\n",
        "def split_into_sentences(text):\n",
        "    sentences = text.split('.')\n",
        "    return [sentence.strip() for sentence in sentences if sentence]\n"
      ],
      "metadata": {
        "id": "1PmzZqf6hFy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom function to calculate cosine similarity with a threshold\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "def cosine_similarity_threshold(embeddings, threshold=0.1):\n",
        "    # Normalize the embeddings\n",
        "    embeddings = normalize(embeddings)\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "    adj_matrix = (sim_matrix > threshold).astype(float)  # Apply threshold to create edges\n",
        "    return adj_matrix\n",
        "\n",
        "\n",
        "# Extract sentence features\n",
        "def extract_sentence_features(sentences):\n",
        "    features = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        length = len(sentence.split())\n",
        "        features.append({\n",
        "            'position': i,\n",
        "            'length': length,\n",
        "            'proper_nouns': sum([1 for token in tokenize_with_spacy(sentence) if token.isupper()]),\n",
        "            'is_first_three': 1 if i < 3 else 0\n",
        "        })\n",
        "    return features\n",
        "\n",
        "# Calculate sentence personalization score\n",
        "def calculate_personalization_scores(features):\n",
        "    weights = {\n",
        "        'position': 0.1,\n",
        "        'length': 0.2,\n",
        "        'proper_nouns': 0.4,\n",
        "        'is_first_three': 0.3\n",
        "    }\n",
        "    personalization_scores = []\n",
        "    for feature in features:\n",
        "        score = sum([feature[key] * weights[key] for key in weights])\n",
        "        personalization_scores.append(score)\n",
        "    return personalization_scores\n",
        "\n",
        "# Build the sentence relation graph using cosine similarity and personalization\n",
        "def build_sentence_relation_graph(sentences, threshold=0.2):\n",
        "    sentence_embeddings = [get_embeddings_with_spacy(sentence) for sentence in sentences]\n",
        "    sentence_embeddings = np.vstack(sentence_embeddings)\n",
        "\n",
        "    adj_matrix = cosine_similarity_threshold(sentence_embeddings, threshold)\n",
        "    sentence_features = extract_sentence_features(sentences)\n",
        "    personalization_scores = calculate_personalization_scores(sentence_features)\n",
        "\n",
        "    for i in range(adj_matrix.shape[0]):\n",
        "        for j in range(adj_matrix.shape[1]):\n",
        "            if adj_matrix[i, j] > 0:\n",
        "                adj_matrix[i, j] *= personalization_scores[i]\n",
        "\n",
        "    adj_matrix = adj_matrix / adj_matrix.max()\n",
        "    return adj_matrix"
      ],
      "metadata": {
        "id": "hX5tcqzvhJZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUSentenceEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUSentenceEncoder, self).__init__()\n",
        "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h_n = self.gru(x)\n",
        "        return h_n.squeeze(0)\n",
        "\n",
        "# Processing document cluster through the GRU\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def process_document_cluster_through_gru(documents, hidden_size=128):\n",
        "    input_size = 300  # SpaCy vectors are 300-dimensional\n",
        "    encoder = GRUSentenceEncoder(input_size, hidden_size).to(device)\n",
        "\n",
        "    sentence_encodings = []\n",
        "    for doc in documents:\n",
        "        sentences = split_into_sentences(doc)\n",
        "        sentence_embeddings = [torch.tensor(get_embeddings_with_spacy(sentence)).to(device) for sentence in sentences]\n",
        "\n",
        "        # Padding sentence embeddings to ensure uniform shape\n",
        "        embeddings_tensor = pad_sequence(sentence_embeddings, batch_first=True).unsqueeze(0).to(device)\n",
        "\n",
        "        # Ensure that the input tensor shape is correct for GRU\n",
        "        sentence_encoding = encoder(embeddings_tensor)\n",
        "        sentence_encodings.append(sentence_encoding)\n",
        "\n",
        "    return torch.stack(sentence_encodings)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gf62oIPvhQfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.fc = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.fc(x)\n",
        "        adj = self.normalize_adj(adj)\n",
        "        x = torch.matmul(adj, x)\n",
        "        return F.relu(x)\n",
        "\n",
        "    def normalize_adj(self, adj):\n",
        "        num_nodes = adj.size(0)\n",
        "        I = torch.eye(num_nodes).to(device)\n",
        "        adj = adj + I\n",
        "        D = torch.sum(adj, dim=1)\n",
        "        D_inv_sqrt = torch.pow(D, -0.5)\n",
        "        D_inv_sqrt[torch.isinf(D_inv_sqrt)] = 0\n",
        "        D_inv_sqrt = torch.diag(D_inv_sqrt)\n",
        "        return torch.matmul(D_inv_sqrt, torch.matmul(adj, D_inv_sqrt))\n",
        "\n"
      ],
      "metadata": {
        "id": "mcHoKj7jhVJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentClusterEncoder(nn.Module):\n",
        "    def __init__(self, sentence_input_size, sentence_hidden_size, doc_input_size, doc_hidden_size):\n",
        "        super(DocumentClusterEncoder, self).__init__()\n",
        "        self.sentence_encoder = GRUSentenceEncoder(sentence_input_size, sentence_hidden_size)\n",
        "        self.doc_encoder = GRUSentenceEncoder(sentence_hidden_size, doc_hidden_size)\n",
        "\n",
        "    def forward(self, document_clusters):\n",
        "        document_embeddings = []\n",
        "\n",
        "        for doc_cluster in document_clusters:\n",
        "            sentence_embeddings = self.sentence_encoder(doc_cluster)\n",
        "            sentence_embeddings = sentence_embeddings.unsqueeze(0)\n",
        "            doc_embedding = self.doc_encoder(sentence_embeddings)\n",
        "            document_embeddings.append(doc_embedding)\n",
        "\n",
        "        document_embeddings = torch.stack(document_embeddings)\n",
        "        cluster_embedding = torch.mean(document_embeddings, dim=0)\n",
        "        return cluster_embedding\n"
      ],
      "metadata": {
        "id": "JO20u008hZOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SalienceEstimator(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(SalienceEstimator, self).__init__()\n",
        "        self.W1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.W2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.v = nn.Parameter(torch.randn(hidden_size))\n",
        "\n",
        "    def forward(self, sentence_embeddings, cluster_embedding):\n",
        "        cluster_embedding = cluster_embedding.unsqueeze(0)\n",
        "        scores = torch.matmul(\n",
        "            F.tanh(self.W1(cluster_embedding) + self.W2(sentence_embeddings)),\n",
        "            self.v\n",
        "        )\n",
        "        salience_scores = F.softmax(scores.squeeze(0), dim=0)\n",
        "        return salience_scores\n"
      ],
      "metadata": {
        "id": "GshD-wiRhav7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the device to use: GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Read and process documents\n",
        "documents = read_document_cluster(summaries_dir)\n",
        "sentences_per_document = [split_into_sentences(doc) for doc in documents]\n",
        "# first_document = documents[0]\n",
        "# sentences_per_document = split_into_sentences(first_document)\n",
        "\n",
        "print(\"done with sentences\")\n",
        "\n",
        "# Build sentence relation graphs for each document\n",
        "adj_matrices = [build_sentence_relation_graph(sentences) for sentences in sentences_per_document]\n",
        "print(\"done with adj_matrices\")\n",
        "\n",
        "# Process documents through GRU\n",
        "sentence_encodings = process_document_cluster_through_gru(documents, hidden_size=128)\n",
        "#sentence_encodings = process_document_cluster_through_gru([first_document], hidden_size=128)\n",
        "print(\"done with encodings\")\n",
        "\n",
        "# Example usage of GCN layer\n",
        "gcn = GCNLayer(128, 64).to(device)\n",
        "adj_tensor = torch.tensor(adj_matrices[0], dtype=torch.float32).to(device)\n",
        "sentence_encodings = sentence_encodings.to(device)\n",
        "\n",
        "# Check the shape of the sentence encodings\n",
        "# Check the shape of the sentence encodings\n",
        "print(f\"Shape of sentence_encodings before: {sentence_encodings.shape}\")\n",
        "\n",
        "# Ensure that the encodings have the correct dimensions [num_sentences, embedding_size]\n",
        "if len(sentence_encodings.shape) == 3 and sentence_encodings.shape[1] == 1:\n",
        "    sentence_encodings = sentence_encodings.squeeze(1)  # Remove extra dimension if needed\n",
        "\n",
        "print(f\"Shape of sentence_encodings after: {sentence_encodings.shape}\")\n",
        "\n",
        "# Apply the GCN layer to the sentence encodings and adjacency matrix\n",
        "gcn_output = gcn(sentence_encodings, adj_tensor)\n",
        "\n",
        "print(\"GCN output: \", gcn_output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "CKQ_zDpihdjz",
        "outputId": "c5977c18-c093-4ec6-ebd4-25190b5eab2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done with sentences\n",
            "done with adj_matrices\n",
            "done with encodings\n",
            "Shape of sentence_encodings before: torch.Size([608, 1, 128])\n",
            "Shape of sentence_encodings after: torch.Size([608, 1, 128])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected size for first two dimensions of batch2 tensor to be: [608, 331] but got: [608, 1].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-470ef8bbb6e1>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Apply the GCN layer to the sentence encodings and adjacency matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mgcn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GCN output: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ecbf5b01b0cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_adj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [608, 331] but got: [608, 1]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from rouge_score import rouge_scorer  # Ensure rouge_score is installed: pip install rouge-score\n",
        "\n",
        "# Function to read document clusters from the dataset directory\n",
        "def read_document_cluster(summaries_dir):\n",
        "    documents = []\n",
        "    summaries_files = os.listdir(summaries_dir)\n",
        "\n",
        "    for file_name in summaries_files:\n",
        "        file_path = os.path.join(summaries_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                documents.append(file.read())\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_name}: {e}\")\n",
        "    return documents\n",
        "\n",
        "# Function to read reference summaries\n",
        "def read_reference_summaries(reference_dir):\n",
        "    references = {}\n",
        "    summaries_files = os.listdir(reference_dir)\n",
        "\n",
        "    for file_name in summaries_files:\n",
        "        file_path = os.path.join(reference_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                references[file_name] = file.read()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_name}: {e}\")\n",
        "    return references\n",
        "\n",
        "# Sentence selection function\n",
        "def select_sentences(salience_scores, sentences, length_limit=55, redundancy_threshold=0.5):\n",
        "    if salience_scores.dim() > 1:\n",
        "        salience_scores = salience_scores.squeeze(0)\n",
        "\n",
        "    scores, indices = torch.sort(salience_scores, descending=True)\n",
        "    selected_sentences = []\n",
        "    current_length = 0\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    for idx in indices:\n",
        "        sentence = sentences[idx]\n",
        "        sentence_length = len(sentence.split())\n",
        "\n",
        "        if current_length + sentence_length > length_limit:\n",
        "            break\n",
        "\n",
        "        if selected_sentences:\n",
        "            all_sentences = selected_sentences + [sentence]\n",
        "            tfidf_matrix = tfidf_vectorizer.fit_transform(all_sentences)\n",
        "            cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
        "\n",
        "            if cosine_similarities.max() > redundancy_threshold:\n",
        "                continue\n",
        "\n",
        "        selected_sentences.append(sentence)\n",
        "        current_length += sentence_length\n",
        "\n",
        "    return selected_sentences\n",
        "\n",
        "# Function to calculate ROUGE scores\n",
        "def calculate_rouge(reference_summary, generated_summary):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(reference_summary, generated_summary)\n",
        "    return scores\n",
        "\n",
        "# Path to the dataset and reference summaries\n",
        "summaries_dir = '/content/drive/My Drive/Colab Notebooks/datasets/final/Whole_text_data'\n",
        "reference_summaries_dir = '/content/drive/My Drive/Colab Notebooks/datasets/final/Summaries'\n",
        "\n",
        "# Read the document cluster from the dataset\n",
        "documents = read_document_cluster(summaries_dir)\n",
        "reference_summaries = read_reference_summaries(reference_summaries_dir)\n",
        "\n",
        "# Example function to get salience scores for sentences (replace with your actual model's output)\n",
        "def get_salience_scores(num_sentences):\n",
        "    return torch.rand(num_sentences)  # Random salience scores for now (replace with model output)\n",
        "\n",
        "# Iterate over each document, generate a summary, and compute ROUGE scores\n",
        "for doc_name, doc in zip(reference_summaries.keys(), documents):\n",
        "    # Split document into sentences (you can replace this with a more sophisticated tokenizer)\n",
        "    sentences = doc.split('. ')  # Simple sentence splitting by '. ' (adjust based on your data)\n",
        "\n",
        "    # Get salience scores for each sentence (replace with your actual method)\n",
        "    salience_scores = get_salience_scores(len(sentences))\n",
        "\n",
        "    # Generate summary using sentence selection\n",
        "    generated_summary_sentences = select_sentences(salience_scores, sentences, length_limit=100)\n",
        "    generated_summary = ' '.join(generated_summary_sentences)\n",
        "\n",
        "    # Get reference summary\n",
        "    reference_summary = reference_summaries.get(doc_name, \"Reference summary not found\")  # Fallback text\n",
        "\n",
        "    # Calculate ROUGE scores\n",
        "    rouge_scores = calculate_rouge(reference_summary, generated_summary)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Document: {doc_name}\")\n",
        "    print(\"Generated Summary:\")\n",
        "    print(generated_summary)\n",
        "    print(\"\\nROUGE Scores:\", rouge_scores)\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "QOfdNDtAjUKJ",
        "outputId": "1b636428-a006-4459-d238-14d9752fe422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'rouge_score'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-477084837f0f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrouge_scorer\u001b[0m  \u001b[0;31m# Ensure rouge_score is installed: pip install rouge-score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Function to read document clusters from the dataset directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rouge_score'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ER4QDNXg1MEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complete Code\n"
      ],
      "metadata": {
        "id": "u3qUvteQ25OO"
      }
    }
  ]
}